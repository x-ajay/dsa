# Time Complexity Documentation

## Overview

Time complexity is a crucial concept in computer science that helps us understand the efficiency of an algorithm. It does not refer to the actual time taken by a code to execute but rather to the number of times a particular statement within the code is executed as the input size grows.

## Key Concepts

### Time Complexity

- **Time Complexity** is a measure of the amount of computational work required by an algorithm as a function of the input size.

### Notations

- **Big O (O)**: Represents the *upper bound* of the time complexity, providing an upper limit on the growth rate of the runtime.
- **Omega (Î©)**: Represents the *lower bound* of the time complexity, giving a lower limit on how little time an algorithm might take in the best-case scenario.

## Further Reading

For a more detailed explanation and examples, refer to the [GeeksforGeeks article on Time Complexity](https://www.geeksforgeeks.org/understanding-time-complexity-simple-examples/).

## Visual Example

Here is an example image that illustrates various time complexities:

![time complexity examples](./assets/time-complexity-examples.png "time complexity")

## Additional Resources

To gain a deeper understanding of time complexity and see examples of how it applies to different algorithms, you can check out this [YouTube playlist](https://www.youtube.com/playlist?list=PLUcsbZa0qzu3yNzzAxgvSgRobdUUJvz7p).

This playlist covers a variety of topics and provides practical examples that are beneficial for both beginners and advanced learners.